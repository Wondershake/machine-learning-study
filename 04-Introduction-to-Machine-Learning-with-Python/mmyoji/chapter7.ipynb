{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Ch7. テキストデータの処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mdata/aclImdb\u001b[00m\r\n",
      "├── \u001b[01;34mtest\u001b[00m\r\n",
      "│   ├── \u001b[01;34mneg\u001b[00m\r\n",
      "│   └── \u001b[01;34mpos\u001b[00m\r\n",
      "└── \u001b[01;34mtrain\u001b[00m\r\n",
      "    ├── \u001b[01;34mneg\u001b[00m\r\n",
      "    ├── \u001b[01;34mpos\u001b[00m\r\n",
      "    └── \u001b[01;34munsup\u001b[00m\r\n",
      "\r\n",
      "7 directories\r\n"
     ]
    }
   ],
   "source": [
    "!tree -dL 2 data/aclImdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r data/aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of text_train: <class 'list'>\n",
      "length of text_train: 25000\n",
      "text_train[1]:\n",
      " b'Words can\\'t describe how bad this movie is. I can\\'t explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do that. There are so many clich\\xc3\\xa9s, mistakes (and all other negative things you can imagine) here that will just make you cry. To start with the technical first, there are a LOT of mistakes regarding the airplane. I won\\'t list them here, but just mention the coloring of the plane. They didn\\'t even manage to show an airliner in the colors of a fictional airline, but instead used a 747 painted in the original Boeing livery. Very bad. The plot is stupid and has been done many times before, only much, much better. There are so many ridiculous moments here that i lost count of it really early. Also, I was on the bad guys\\' side all the time in the movie, because the good guys were so stupid. \"Executive Decision\" should without a doubt be you\\'re choice over this one, even the \"Turbulence\"-movies are better. In fact, every other movie in the world is better than this one.'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews_train = load_files(\"data/aclImdb/train/\")\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "\n",
    "print(f\"type of text_train: {type(text_train)}\")\n",
    "print(f\"length of text_train: {len(text_train)}\")\n",
    "print(f\"text_train[1]:\\n {text_train[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove <br/> tag\n",
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per class (training): [12500 12500]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Samples per class (training): {np.bincount(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text_test: 25000\n",
      "Samples per class (test): [12500 12500]\n"
     ]
    }
   ],
   "source": [
    "reviews_test = load_files(\"data/aclImdb/test/\")\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "\n",
    "print(f\"length of text_test: {len(text_test)}\")\n",
    "print(f\"Samples per class (test): {np.bincount(y_test)}\")\n",
    "\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 13\n",
      "Vocabulary content:\n",
      " {'the': 9, 'fool': 3, 'doth': 2, 'think': 10, 'he': 4, 'is': 6, 'wise': 12, 'but': 1, 'man': 8, 'knows': 7, 'himself': 5, 'to': 11, 'be': 0}\n"
     ]
    }
   ],
   "source": [
    "bards_words = [\"The fool doth think he is wise,\", \"but the wise man knows  himself to be a fool\"]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "vect.fit(bards_words)\n",
    "\n",
    "print(f\"Vocabulary size: {len(vect.vocabulary_)}\")\n",
    "print(f\"Vocabulary content:\\n {vect.vocabulary_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag_of_words: <2x13 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = vect.transform(bards_words)\n",
    "print(f\"bag_of_words: {repr(bag_of_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense representation of bag_of_words:\n",
      "[[0 0 1 1 1 0 1 0 0 1 1 0 1]\n",
      " [1 1 0 1 0 1 0 1 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dense representation of bag_of_words:\\n{bag_of_words.toarray()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      " <25000x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3431196 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(f\"X_train:\\n {repr(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 74849\n",
      "First 20 features:\n",
      "['00', '000', '0000000000001', '00001', '00015', '000s', '001', '003830', '006', '007', '0079', '0080', '0083', '0093638', '00am', '00pm', '00s', '01', '01pm', '02']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "\n",
    "print(f\"Number of features: {len(feature_names)}\")\n",
    "print(f\"First 20 features:\\n{feature_names[:20]}\")\n",
    "# skip some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validation accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), X_train, y_train, cv=5)\n",
    "print(\"Mean cross-validation accuracy: {:.2f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.89\n",
      "Best params:  {'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best params: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n"
     ]
    }
   ],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "print(\"{:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train with min_df: <25000x27271 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3354014 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(f\"X_train with min_df: {repr(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 50 features:\n",
      "['00', '000', '007', '00s', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '100', '1000', '100th', '101', '102', '103', '104', '105', '107', '108', '10s', '10th', '11', '110', '112', '116', '117', '11th', '12', '120', '12th', '13', '135', '13th', '14', '140', '14th', '15', '150', '15th', '16', '160', '1600', '16mm', '16s', '16th']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print(f\"First 50 features:\\n{feature_names[:50]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.89\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train with stop words:\n",
      "<25000x26966 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 2149958 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df=5, stop_words=\"english\").fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "\n",
    "print(f\"X_train with stop words:\\n{repr(X_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.88\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(TfidfVectorizer(min_df=5, norm=None), LogisticRegression())\n",
    "param_grid = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(text_train, y_train)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with lowest tfidf:\n",
      "['poignant' 'disagree' 'instantly' 'importantly' 'lacked' 'occurred'\n",
      " 'currently' 'altogether' 'nearby' 'undoubtedly' 'directs' 'fond' 'stinker'\n",
      " 'avoided' 'emphasis' 'commented' 'disappoint' 'realizing' 'downhill'\n",
      " 'inane']\n",
      "Features with highest tfidf:\n",
      "['coop' 'homer' 'dillinger' 'hackenstein' 'gadget' 'taker' 'macarthur'\n",
      " 'vargas' 'jesse' 'basket' 'dominick' 'the' 'victor' 'bridget' 'victoria'\n",
      " 'khouri' 'zizek' 'rob' 'timon' 'titanic']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = grid.best_estimator_.named_steps[\"tfidfvectorizer\"]\n",
    "X_train = vectorizer.transform(text_train)\n",
    "max_value = X_train.max(axis=0).toarray().ravel()\n",
    "sorted_byidf = max_value.argsort()\n",
    "feature_names = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "print(\"Features with lowest tfidf:\\n{}\".format(feature_names[sorted_byidf[:20]]))\n",
    "print(\"Features with highest tfidf:\\n{}\".format(feature_names[sorted_byidf[-20:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with lowest idf:\n",
      "['the' 'and' 'of' 'to' 'this' 'is' 'it' 'in' 'that' 'but' 'for' 'with'\n",
      " 'was' 'as' 'on' 'movie' 'not' 'have' 'one' 'be' 'film' 'are' 'you' 'all'\n",
      " 'at' 'an' 'by' 'so' 'from' 'like' 'who' 'they' 'there' 'if' 'his' 'out'\n",
      " 'just' 'about' 'he' 'or' 'has' 'what' 'some' 'good' 'can' 'more' 'when'\n",
      " 'time' 'up' 'very' 'even' 'only' 'no' 'would' 'my' 'see' 'really' 'story'\n",
      " 'which' 'well' 'had' 'me' 'than' 'much' 'their' 'get' 'were' 'other'\n",
      " 'been' 'do' 'most' 'don' 'her' 'also' 'into' 'first' 'made' 'how' 'great'\n",
      " 'because' 'will' 'people' 'make' 'way' 'could' 'we' 'bad' 'after' 'any'\n",
      " 'too' 'then' 'them' 'she' 'watch' 'think' 'acting' 'movies' 'seen' 'its'\n",
      " 'him']\n"
     ]
    }
   ],
   "source": [
    "sorted_byidf = np.argsort(vectorizer.idf_)\n",
    "\n",
    "print(\"Features with lowest idf:\\n{}\".format(feature_names[sorted_byidf[:100]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bards_of_words:\n",
      "['The fool doth think he is wise,', 'but the wise man knows  himself to be a fool']\n"
     ]
    }
   ],
   "source": [
    "print(\"bards_of_words:\\n{}\".format(bards_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 13\n",
      "Vocabulary:\n",
      "['be', 'but', 'doth', 'fool', 'he', 'himself', 'is', 'knows', 'man', 'the', 'think', 'to', 'wise']\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 1)).fit(bards_words)\n",
    "print(f\"Vocabulary size: {len(cv.vocabulary_)}\")\n",
    "print(f\"Vocabulary:\\n{cv.get_feature_names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 14\n",
      "Vocabulary:\n",
      "['be fool', 'but the', 'doth think', 'fool doth', 'he is', 'himself to', 'is wise', 'knows himself', 'man knows', 'the fool', 'the wise', 'think he', 'to be', 'wise man']\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(2, 2)).fit(bards_words)\n",
    "print(f\"Vocabulary size: {len(cv.vocabulary_)}\")\n",
    "print(f\"Vocabulary:\\n{cv.get_feature_names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed data (dense):\n",
      "[[0 0 1 1 1 0 1 0 0 1 0 1 0 0]\n",
      " [1 1 0 0 0 1 0 1 1 0 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Transformed data (dense):\\n{cv.transform(bards_words).toarray()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 39\n",
      "Vocabulary:\n",
      "['be', 'be fool', 'but', 'but the', 'but the wise', 'doth', 'doth think', 'doth think he', 'fool', 'fool doth', 'fool doth think', 'he', 'he is', 'he is wise', 'himself', 'himself to', 'himself to be', 'is', 'is wise', 'knows', 'knows himself', 'knows himself to', 'man', 'man knows', 'man knows himself', 'the', 'the fool', 'the fool doth', 'the wise', 'the wise man', 'think', 'think he', 'think he is', 'to', 'to be', 'to be fool', 'wise', 'wise man', 'wise man knows']\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 3)).fit(bards_words)\n",
    "print(f\"Vocabulary size: {len(cv.vocabulary_)}\")\n",
    "print(f\"Vocabulary:\\n{cv.get_feature_names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.91\n",
      "Best params:  {'logisticregression__C': 100, 'tfidfvectorizer__ngram_range': (1, 3)}\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(min_df=5), LogisticRegression())\n",
    "param_grid = {\"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              \"tfidfvectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(text_train, y_train)\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best params: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization:\n",
      "['-PRON-', 'meeting', 'today', 'be', 'bad', 'than', 'yesterday', ',', \"i'm\", 'scar', 'of', 'meet', 'the', 'client', 'tomorrow', '.']\n",
      "Stemming:\n",
      "['our', 'meet', 'today', 'wa', 'wors', 'than', 'yesterday', ',', \"i'm\", 'scare', 'of', 'meet', 'the', 'client', 'tomorrow', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "\n",
    "en_nlp = spacy.load('en')\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "def compare_normalization(doc):\n",
    "    # Split the doc by tokens\n",
    "    doc_spacy = en_nlp(doc)\n",
    "    \n",
    "    print(\"Lemmatization:\")\n",
    "    print([token.lemma_ for token in doc_spacy])\n",
    "    \n",
    "    print(\"Stemming:\")\n",
    "    print([stemmer.stem(token.norm_.lower()) for token in doc_spacy])\n",
    "    \n",
    "compare_normalization(u\"Our meeting today was worse than yesterday,\"\n",
    "                       \"I'm scared of meeting the clients tomorrow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "regexp = re.compile('(?u)\\\\b\\\\w\\\\w+\\\\b')\n",
    "\n",
    "en_nlp = spacy.load('en')\n",
    "old_tokenizer = en_nlp.tokenizer\n",
    "\n",
    "en_nlp.tokenizer = lambda string: Doc(en_nlp.vocab, words=regexp.findall(string))\n",
    "\n",
    "def custom_tokenizer(document):\n",
    "    doc_spacy = en_nlp(document, disable=['entity', 'parser'])\n",
    "    return [token.lemma_ for token in doc_spacy]\n",
    "\n",
    "lemma_vect = CountVectorizer(tokenizer=custom_tokenizer, min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_lemma.shape: (X_train_lemma.shape)\n",
      "X_train.shape: (25000, 27271)\n"
     ]
    }
   ],
   "source": [
    "X_train_lemma = lemma_vect.fit_transform(text_train)\n",
    "print(f\"X_train_lemma.shape: {X_train_lemma.shape}\")\n",
    "\n",
    "# for comparison\n",
    "vect = CountVectorizer(min_df=5).fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "print(f\"X_train.shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score (standard CountVectorizer): 0.721\n",
      "Best cross-validation score (lemmatization): 0.735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.99, train_size=0.01, random_state=0)\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, cv=cv)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best cross-validation score \"\n",
    "      \"(standard CountVectorizer): {:.3f}\".format(grid.best_score_))\n",
    "grid.fit(X_train_lemma, y_train)\n",
    "print(\"Best cross-validation score \"\n",
    "      \"(lemmatization): {:.3f}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
